#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import json
import re
from datetime import datetime, timedelta, time as dt_time
import requests
from decimal import Decimal

import sys
import os

project_root = os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
sys.path.insert(0, project_root)

from utils.logger import setup_logger
from utils.database import get_connection
from config.config import LLM_CONFIG

logger = setup_logger(__name__)


def convert_decimal(obj):
    if isinstance(obj, Decimal):
        return float(obj)
    elif isinstance(obj, dict):
        return {k: convert_decimal(v) for k, v in obj.items()}
    elif isinstance(obj, list):
        return [convert_decimal(item) for item in obj]
    elif isinstance(obj, tuple):
        return tuple(convert_decimal(item) for item in obj)
    return obj


def safe_float(value, default=0.0):
    try:
        if value is None:
            return default
        return float(value)
    except (ValueError, TypeError):
        return default


def safe_int(value, default=0):
    try:
        if value is None:
            return default
        return int(value)
    except (ValueError, TypeError):
        return default


def safe_datetime_format(dt_obj, format_str='%Y-%m-%d %H:%M:%S'):
    try:
        if dt_obj is None:
            return ''
        if isinstance(dt_obj, str):
            try:
                parsed_dt = datetime.strptime(dt_obj, '%Y-%m-%d %H:%M:%S')
                return parsed_dt.strftime(format_str)
            except:
                return str(dt_obj)
        elif isinstance(dt_obj, datetime):
            return dt_obj.strftime(format_str)
        else:
            return str(dt_obj)
    except Exception as e:
        logger.warning(f"âš ï¸ æ—¥æœŸæ ¼å¼åŒ–å¤±è´¥: {dt_obj}, é”™è¯¯: {e}")
        return str(dt_obj) if dt_obj else ''


def safe_date_format(date_obj, format_str='%Y-%m-%d'):
    try:
        if date_obj is None:
            return ''
        if isinstance(date_obj, str):
            return str(date_obj)
        elif hasattr(date_obj, 'strftime'):
            return date_obj.strftime(format_str)
        else:
            return str(date_obj)
    except Exception as e:
        logger.warning(f"âš ï¸ æ—¥æœŸæ ¼å¼åŒ–å¤±è´¥: {date_obj}, é”™è¯¯: {e}")
        return str(date_obj) if date_obj else ''


def get_daily_date_range():
    today = datetime.now().date()
    yesterday = today - timedelta(days=1)
    yesterday_start = datetime.combine(yesterday, dt_time.min)
    yesterday_end = datetime.combine(yesterday, dt_time.max)
    return yesterday_start, yesterday_end, yesterday


def generate_unique_id(prefix='oas'):
    timestamp = datetime.now().strftime('%Y%m%d%H%M%S')
    return f"{prefix}{timestamp}"


def fetch_server_metrics(conn, start_time, end_time):
    print(f"    ğŸ“Š å¯åŠ¨æ•°æ®åº“è¿æ¥ï¼ŒæŸ¥è¯¢æœåŠ¡å™¨æ€§èƒ½æŒ‡æ ‡...")
    with conn.cursor() as cursor:
        query = """
                SELECT ip,
                       cpu_usage,
                       cpu_status,
                       memory_usage,
                       memory_status,
                       disk_usage,
                       disk_status,
                       network_status,
                       packet_loss_status,
                       user_load_status,
                       collect_time
                FROM howso_server_performance_metrics
                WHERE collect_time BETWEEN %s AND %s
                """
        cursor.execute(query, (start_time, end_time))
        results = cursor.fetchall()
        print(f"    âœ… æœåŠ¡å™¨æ€§èƒ½æ•°æ®é‡‡é›†å®Œæˆï¼Œå…±è·å– {len(results)} æ¡æ€§èƒ½è®°å½•")
        return [dict(zip([desc[0] for desc in cursor.description], convert_decimal(row))) for row in results]


def fetch_service_status(conn, start_time, end_time):
    print(f"    ğŸ”§ æŸ¥è¯¢æœåŠ¡çŠ¶æ€ç›‘æ§æ•°æ®...")
    with conn.cursor() as cursor:
        query = """
                SELECT platform,
                       server_name,
                       server_ip,
                       service_name,
                       status,
                       process_status,
                       response_time,
                       insert_time
                FROM plat_service_monitoring
                WHERE insert_time BETWEEN %s AND %s
                """
        cursor.execute(query, (start_time, end_time))
        results = cursor.fetchall()
        print(f"    âœ… æœåŠ¡çŠ¶æ€æ•°æ®é‡‡é›†å®Œæˆï¼Œå…±è·å– {len(results)} æ¡æœåŠ¡è®°å½•")
        return [dict(zip([desc[0] for desc in cursor.description], convert_decimal(row))) for row in results]


def fetch_nas_pools(conn, start_date, end_date):
    print(f"    ğŸ’¾ æŸ¥è¯¢å­˜å‚¨æ± ç›‘æ§æ•°æ®...")
    with conn.cursor() as cursor:
        query = """
                SELECT server_name,
                       pool_name,
                       used_space,
                       used_space_unit,
                       available_space,
                       available_space_unit,
                       usage_percentage,
                       status,
                       inspection_date,
                       inspection_time
                FROM nas_pools_detail
                WHERE inspection_date BETWEEN %s AND %s
                """
        cursor.execute(query, (start_date, end_date))
        results = cursor.fetchall()
        print(f"    âœ… å­˜å‚¨æ± æ•°æ®é‡‡é›†å®Œæˆï¼Œå…±è·å– {len(results)} æ¡å­˜å‚¨è®°å½•")
        return [dict(zip([desc[0] for desc in cursor.description], convert_decimal(row))) for row in results]


def fetch_power_monitoring(conn, start_time, end_time):
    try:
        print(f"    âš¡ æŸ¥è¯¢ç”µåŠ›ç›‘æ§æ•°æ®...")
        with conn.cursor() as cursor:
            twelve_hours_ago = datetime.now() - timedelta(hours=12)
            query = """
                    SELECT battery_status,
                           ups_supply_time,
                           avg_input_voltage,
                           avg_input_voltage_status,
                           avg_output_voltage,
                           avg_output_voltage_status,
                           avg_input_current,
                           avg_input_current_status,
                           avg_output_current,
                           avg_output_current_status,
                           avg_temperature,
                           avg_temperature_status,
                           avg_humidity,
                           avg_humidity_status,
                           inspection_time
                    FROM power_monitoring_avg_data
                    WHERE inspection_time >= %s
                    ORDER BY inspection_time DESC
                    """
            cursor.execute(query, (twelve_hours_ago,))
            results = cursor.fetchall()
            print(f"    âœ… ç”µåŠ›ç›‘æ§æ•°æ®é‡‡é›†å®Œæˆï¼Œå…±è·å– {len(results)} æ¡ç”µåŠ›è®°å½•")
            return [dict(zip([desc[0] for desc in cursor.description], convert_decimal(row))) for row in results]
    except Exception as e:
        print(f"    âš ï¸ ç”µåŠ›ç›‘æ§æ•°æ®é‡‡é›†é‡åˆ°é—®é¢˜: {e}")
        logger.error(f"ğŸš¨ Error fetching power monitoring data: {e}")
        return []


def format_timedelta_as_time(td):
    total_seconds = int(td.total_seconds())
    hours, remainder = divmod(total_seconds, 3600)
    minutes, seconds = divmod(remainder, 60)
    return f"{hours:02d}:{minutes:02d}:{seconds:02d}"


def get_exceptions(server_metrics, service_status, nas_pools, power_monitoring):
    print(f"    ğŸ” å¼€å§‹è¯†åˆ«å’Œåˆ†æå¼‚å¸¸æ•°æ®...")
    
    exceptions = {
        "æœåŠ¡å™¨å¼‚å¸¸": [],
        "æœåŠ¡å¼‚å¸¸": [],
        "å­˜å‚¨å¼‚å¸¸": [],
        "ç”µåŠ›å¼‚å¸¸": []
    }

    for metric in server_metrics:
        if (metric.get('cpu_status') != 'æ­£å¸¸' or
                metric.get('memory_status') != 'æ­£å¸¸' or
                metric.get('disk_status') != 'æ­£å¸¸' or
                metric.get('network_status') != 'æ­£å¸¸' or
                metric.get('packet_loss_status') != 'æ­£å¸¸' or
                metric.get('user_load_status') != 'æ­£å¸¸'):

            exception_item = {
                "IP": metric.get('ip', ''),
                "æ—¶é—´": safe_datetime_format(metric.get('collect_time'))
            }

            if metric.get('cpu_status') != 'æ­£å¸¸':
                exception_item["CPUçŠ¶æ€"] = f"{metric.get('cpu_usage')}% ({metric.get('cpu_status')})"
            if metric.get('memory_status') != 'æ­£å¸¸':
                exception_item["å†…å­˜çŠ¶æ€"] = f"{metric.get('memory_usage')}% ({metric.get('memory_status')})"
            if metric.get('disk_status') != 'æ­£å¸¸':
                exception_item["ç£ç›˜çŠ¶æ€"] = f"{metric.get('disk_usage')}% ({metric.get('disk_status')})"
            if metric.get('network_status') != 'æ­£å¸¸':
                exception_item["ç½‘ç»œçŠ¶æ€"] = metric.get('network_status')
            if metric.get('packet_loss_status') != 'æ­£å¸¸':
                exception_item["ä¸¢åŒ…çŠ¶æ€"] = metric.get('packet_loss_status')
            if metric.get('user_load_status') != 'æ­£å¸¸':
                exception_item["ç”¨æˆ·è´Ÿè½½çŠ¶æ€"] = metric.get('user_load_status')

            exceptions["æœåŠ¡å™¨å¼‚å¸¸"].append(exception_item)

    for service in service_status:
        if service.get('status') != 'æ­£å¸¸' or service.get('process_status') == 'æœªè¿è¡Œ':
            exceptions["æœåŠ¡å¼‚å¸¸"].append({
                "å¹³å°": service.get('platform', ''),
                "æœåŠ¡å™¨": f"{service.get('server_name', '')}({service.get('server_ip', '')})",
                "æœåŠ¡åç§°": service.get('service_name', ''),
                "çŠ¶æ€": service.get('status', ''),
                "è¿›ç¨‹çŠ¶æ€": service.get('process_status', ''),
                "å“åº”æ—¶é—´": service.get('response_time', ''),
                "æ£€æµ‹æ—¶é—´": safe_datetime_format(service.get('insert_time'))
            })

    for pool in nas_pools:
        if pool.get('status') != 'æ­£å¸¸':
            inspection_time_str = ""
            if isinstance(pool.get('inspection_time'), timedelta):
                inspection_time_str = format_timedelta_as_time(pool.get('inspection_time'))
            else:
                try:
                    if hasattr(pool.get('inspection_time'), 'strftime'):
                        inspection_time_str = pool.get('inspection_time').strftime('%H:%M:%S')
                    else:
                        inspection_time_str = str(pool.get('inspection_time', ''))
                except:
                    inspection_time_str = str(pool.get('inspection_time', ''))

            exceptions["å­˜å‚¨å¼‚å¸¸"].append({
                "æœåŠ¡å™¨": pool.get('server_name', ''),
                "å­˜å‚¨æ± ": pool.get('pool_name', ''),
                "å·²ç”¨ç©ºé—´": f"{pool.get('used_space', '')} {pool.get('used_space_unit', '')}",
                "å¯ç”¨ç©ºé—´": f"{pool.get('available_space', '')} {pool.get('available_space_unit', '')}",
                "ä½¿ç”¨ç‡": f"{pool.get('usage_percentage', '')}%",
                "çŠ¶æ€": pool.get('status', ''),
                "æ£€æµ‹æ—¥æœŸ": safe_date_format(pool.get('inspection_date')),
                "æ£€æµ‹æ—¶é—´": inspection_time_str
            })

    for power in power_monitoring:
        if (power.get('battery_status') != 'æ­£å¸¸' or
                power.get('avg_input_voltage_status') != 'æ­£å¸¸' or
                power.get('avg_output_voltage_status') != 'æ­£å¸¸' or
                power.get('avg_input_current_status') != 'æ­£å¸¸' or
                power.get('avg_output_current_status') != 'æ­£å¸¸' or
                power.get('avg_temperature_status') != 'æ­£å¸¸' or
                power.get('avg_humidity_status') != 'æ­£å¸¸'):

            power_item = {
                "æ£€æµ‹æ—¶é—´": safe_datetime_format(power.get('inspection_time')),
                "ç”µæ± çŠ¶æ€": power.get('battery_status', ''),
                "UPSä¾›ç”µæ—¶é—´": f"{power.get('ups_supply_time', '')}åˆ†é’Ÿ"
            }

            if power.get('avg_input_voltage_status') != 'æ­£å¸¸':
                power_item["è¾“å…¥ç”µå‹"] = f"{power.get('avg_input_voltage')}V ({power.get('avg_input_voltage_status')})"
            if power.get('avg_output_voltage_status') != 'æ­£å¸¸':
                power_item[
                    "è¾“å‡ºç”µå‹"] = f"{power.get('avg_output_voltage')}V ({power.get('avg_output_voltage_status')})"
            if power.get('avg_input_current_status') != 'æ­£å¸¸':
                power_item["è¾“å…¥ç”µæµ"] = f"{power.get('avg_input_current')}A ({power.get('avg_input_current_status')})"
            if power.get('avg_output_current_status') != 'æ­£å¸¸':
                power_item[
                    "è¾“å‡ºç”µæµ"] = f"{power.get('avg_output_current')}A ({power.get('avg_output_current_status')})"
            if power.get('avg_temperature_status') != 'æ­£å¸¸':
                power_item["æ¸©åº¦"] = f"{power.get('avg_temperature')}Â°C ({power.get('avg_temperature_status')})"
            if power.get('avg_humidity_status') != 'æ­£å¸¸':
                power_item["æ¹¿åº¦"] = f"{power.get('avg_humidity')}% ({power.get('avg_humidity_status')})"

            exceptions["ç”µåŠ›å¼‚å¸¸"].append(power_item)

    filtered_exceptions = {k: v for k, v in exceptions.items() if v}
    print(f"    âœ… å¼‚å¸¸æ•°æ®è¯†åˆ«å®Œæˆï¼Œå‘ç° {len(filtered_exceptions)} ç±»å¼‚å¸¸æƒ…å†µ")
    
    return filtered_exceptions


def limit_exception_data(exception_data, max_items_per_category=50):
    print(f"    ğŸ”§ ä¼˜åŒ–å¼‚å¸¸æ•°æ®ç»“æ„ï¼Œé¿å…AIæ¨¡å‹tokené™åˆ¶...")
    
    limited_data = {}
    total_limited = 0

    for category, exceptions in exception_data.items():
        if exceptions:
            original_count = len(exceptions)
            limited_exceptions = exceptions[:max_items_per_category]
            limited_data[category] = limited_exceptions

            if original_count > max_items_per_category:
                limited_count = original_count - max_items_per_category
                total_limited += limited_count
                print(f"    ğŸ“Š {category}: åŸæœ‰{original_count}æ¡å¼‚å¸¸ï¼Œä¼˜åŒ–ä¸º{max_items_per_category}æ¡")
                logger.info(
                    f"ğŸ“Š {category}: åŸæœ‰{original_count}æ¡å¼‚å¸¸ï¼Œé™åˆ¶ä¸º{max_items_per_category}æ¡ï¼Œçœç•¥äº†{limited_count}æ¡")

    if total_limited > 0:
        print(f"    âœ… æ•°æ®ä¼˜åŒ–å®Œæˆï¼Œå…±ä¼˜åŒ–{total_limited}æ¡å¼‚å¸¸æ•°æ®")
        logger.info(f"ğŸ“Š æ€»å…±çœç•¥äº†{total_limited}æ¡å¼‚å¸¸æ•°æ®ä»¥é€‚åº”AIæ¨¡å‹é™åˆ¶")

    return limited_data


def format_exception_data_for_storage(exception_data):
    if not exception_data:
        return json.dumps({"summary": "æ— å¼‚å¸¸æ•°æ®", "details": {}}, ensure_ascii=False)

    summary = {}
    formatted_details = {}

    for category, exceptions in exception_data.items():
        if exceptions:
            summary[category] = f"{len(exceptions)}æ¡å¼‚å¸¸"
            formatted_details[category] = []

            for i, exc in enumerate(exceptions, 1):
                formatted_exc = {
                    "åºå·": i,
                    "è¯¦æƒ…": exc
                }
                formatted_details[category].append(formatted_exc)

    result = {
        "å¼‚å¸¸æ‘˜è¦": summary,
        "å¼‚å¸¸æ€»æ•°": sum(len(exceptions) for exceptions in exception_data.values()),
        "ç”Ÿæˆæ—¶é—´": datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
        "è¯¦ç»†ä¿¡æ¯": formatted_details
    }

    return json.dumps(result, ensure_ascii=False, indent=2)


def prepare_data_summary(server_metrics, service_status, nas_pools, power_monitoring):
    print(f"    ğŸ“ˆ å¼€å§‹èšåˆå’Œåˆ†ææ—¥åº¦ç›‘æ§æ•°æ®...")
    
    server_ips = set([m.get('ip') for m in server_metrics if m.get('ip')])
    abnormal_cpu = sum(1 for m in server_metrics if m.get('cpu_status') != 'æ­£å¸¸')
    abnormal_memory = sum(1 for m in server_metrics if m.get('memory_status') != 'æ­£å¸¸')
    abnormal_disk = sum(1 for m in server_metrics if m.get('disk_status') != 'æ­£å¸¸')
    abnormal_network = sum(1 for m in server_metrics if m.get('network_status') != 'æ­£å¸¸')
    abnormal_packet_loss = sum(1 for m in server_metrics if m.get('packet_loss_status') != 'æ­£å¸¸')
    abnormal_user_load = sum(1 for m in server_metrics if m.get('user_load_status') != 'æ­£å¸¸')

    services = len(service_status)
    abnormal_services = sum(1 for s in service_status if s.get('status') != 'æ­£å¸¸')
    stopped_processes = sum(1 for s in service_status if s.get('process_status') == 'æœªè¿è¡Œ')
    platforms = set([s.get('platform') for s in service_status if s.get('platform')])

    total_pools = len(nas_pools)
    abnormal_pools = sum(1 for p in nas_pools if p.get('status') != 'æ­£å¸¸')
    high_usage_pools = sum(1 for p in nas_pools if safe_float(p.get('usage_percentage', 0)) > 80)

    power_records = len(power_monitoring)
    abnormal_battery = sum(1 for p in power_monitoring if p.get('battery_status') != 'æ­£å¸¸')
    abnormal_voltage = sum(1 for p in power_monitoring if
                           p.get('avg_input_voltage_status') != 'æ­£å¸¸' or p.get('avg_output_voltage_status') != 'æ­£å¸¸')
    abnormal_current = sum(1 for p in power_monitoring if
                           p.get('avg_input_current_status') != 'æ­£å¸¸' or p.get('avg_output_current_status') != 'æ­£å¸¸')
    abnormal_env = sum(
        1 for p in power_monitoring if
        p.get('avg_temperature_status') != 'æ­£å¸¸' or p.get('avg_humidity_status') != 'æ­£å¸¸')

    print(f"    âœ… æ—¥åº¦æ•°æ®èšåˆå®Œæˆï¼Œç”Ÿæˆç»Ÿè®¡åˆ†æç»“æœ")

    return {
        "æœåŠ¡å™¨çŠ¶æ€": {
            "æ€»æœåŠ¡å™¨æ•°": len(server_ips),
            "ç›‘æ§è®°å½•æ•°": len(server_metrics),
            "CPUå¼‚å¸¸": abnormal_cpu,
            "å†…å­˜å¼‚å¸¸": abnormal_memory,
            "ç£ç›˜å¼‚å¸¸": abnormal_disk,
            "ç½‘ç»œå¼‚å¸¸": abnormal_network,
            "ä¸¢åŒ…å¼‚å¸¸": abnormal_packet_loss,
            "ç”¨æˆ·è´Ÿè½½å¼‚å¸¸": abnormal_user_load
        },
        "æœåŠ¡çŠ¶æ€": {
            "å¹³å°æ•°é‡": len(platforms),
            "æœåŠ¡æ€»æ•°": services,
            "å¼‚å¸¸æœåŠ¡": abnormal_services,
            "æœªè¿è¡Œè¿›ç¨‹": stopped_processes
        },
        "å­˜å‚¨çŠ¶æ€": {
            "å­˜å‚¨æ± æ€»æ•°": total_pools,
            "å¼‚å¸¸å­˜å‚¨æ± ": abnormal_pools,
            "é«˜ä½¿ç”¨ç‡å­˜å‚¨æ± (>80%)": high_usage_pools
        },
        "ç”µåŠ›çŠ¶æ€": {
            "ç›‘æ§è®°å½•æ•°": power_records,
            "ç”µæ± å¼‚å¸¸": abnormal_battery,
            "ç”µå‹å¼‚å¸¸": abnormal_voltage,
            "ç”µæµå¼‚å¸¸": abnormal_current,
            "ç¯å¢ƒå¼‚å¸¸(æ¸©åº¦/æ¹¿åº¦)": abnormal_env
        }
    }


def parse_ai_response(ai_response):
    print(f"    ğŸ§  å¼€å§‹è§£æAIåˆ†æç»“æœ...")
    
    sections = {
        "è¿ç»´æ—¥æŠ¥": "",
        "å¼‚å¸¸åˆ†æ": "",
        "é£é™©é¢„æµ‹": "",
        "è¿ç»´å»ºè®®": "",
        "é‡ç‚¹å…³æ³¨": "",
        "ä¸­åº¦å…³æ³¨": ""
    }

    pattern = r"#{1,3}\s*(?:\d+\.\s*)?([\u4e00-\u9fa5]+)(?:\s*[ï¼ˆ\(].*[ï¼‰\)])?(?:ï¼ˆ\d+å­—ï¼‰)?\s*([\s\S]*?)(?=#{1,3}\s*(?:\d+\.\s*)?[\u4e00-\u9fa5]+|---+|\n\n\n|$)"
    matches = re.findall(pattern, ai_response)

    for title, content in matches:
        for section in sections.keys():
            if section in title:
                clean_content = content.strip()
                clean_content = re.sub(r'^\s*\d+\.\s*', '', clean_content, flags=re.MULTILINE)
                clean_content = re.sub(r'[\*\-]{1,3}\s+', '', clean_content, flags=re.MULTILINE)
                clean_content = re.sub(r'\n+', ' ', clean_content)
                clean_content = re.sub(r'\s+', ' ', clean_content)
                clean_content = clean_content.replace('---', '')
                sections[section] = clean_content.strip()
                break

    if not any(sections.values()):
        current_section = None
        content_buffer = []
        lines = ai_response.split('\n')
        for line in lines:
            line = line.strip()
            if not line or line.startswith('---'):
                continue
            section_match = False
            for section in sections.keys():
                if section in line and (
                        line.startswith(section) or
                        re.search(r'\d+\.\s+' + section, line) or
                        re.match(r'^#+\s*' + section, line) or
                        re.match(r'^#+\s*\d+\.\s*' + section, line) or
                        re.match(r'^' + section + r'\s*[ï¼ˆ(]', line)
                ):
                    if current_section and content_buffer:
                        sections[current_section] = ' '.join(content_buffer).strip()
                    current_section = section
                    content_buffer = []
                    section_match = True
                    break
            if not section_match and current_section:
                if not line.startswith('#'):
                    content_buffer.append(line)
        if current_section and content_buffer:
            sections[current_section] = ' '.join(content_buffer).strip()

    print(f"    âœ… AIåˆ†æç»“æœè§£æå®Œæˆï¼Œç”Ÿæˆç»“æ„åŒ–æŠ¥å‘Š")
    return sections


def test_ai_connection():
    try:
        print(f"    ğŸ”— æµ‹è¯•AIè¿ç»´å¤§è„‘è¿æ¥çŠ¶æ€...")
        
        url = f"{LLM_CONFIG['base_url']}{LLM_CONFIG['chat_endpoint']}"

        test_payload = {
            "model": LLM_CONFIG['model_name'],
            "messages": [
                {"role": "user", "content": "ä½ å¥½ï¼Œè¯·å›å¤'è¿æ¥æ­£å¸¸'"}
            ],
            "max_tokens": 10
        }

        headers = {
            "Content-Type": "application/json",
            "Accept": "application/json"
        }

        logger.info(f"ğŸ” æµ‹è¯•AIè¿æ¥: {url}")
        response = requests.post(url, json=test_payload, headers=headers, timeout=30, verify=False)

        if response.status_code == 200:
            result = response.json()
            if "choices" in result and result["choices"]:
                print(f"    âœ… AIè¿ç»´å¤§è„‘è¿æ¥æ­£å¸¸")
                logger.info("ğŸ¯ AIæœåŠ¡è¿æ¥æµ‹è¯•æˆåŠŸ")
                return True, "è¿æ¥æ­£å¸¸"
            else:
                print(f"    âŒ AIè¿ç»´å¤§è„‘å“åº”æ ¼å¼å¼‚å¸¸")
                logger.error(f"ğŸš¨ AIæœåŠ¡å“åº”æ ¼å¼å¼‚å¸¸: {result}")
                return False, f"å“åº”æ ¼å¼å¼‚å¸¸: {result}"
        else:
            print(f"    âŒ AIè¿ç»´å¤§è„‘è¿æ¥å¤±è´¥ï¼ŒçŠ¶æ€ç : {response.status_code}")
            logger.error(f"ğŸš¨ AIæœåŠ¡è¿æ¥æµ‹è¯•å¤±è´¥ï¼ŒçŠ¶æ€ç : {response.status_code}")
            logger.error(f"ğŸš¨ å“åº”å†…å®¹: {response.text}")
            return False, f"çŠ¶æ€ç : {response.status_code}, å“åº”: {response.text}"

    except Exception as e:
        print(f"    âŒ AIè¿ç»´å¤§è„‘è¿æ¥æµ‹è¯•å¼‚å¸¸: {e}")
        logger.error(f"ğŸš¨ AIæœåŠ¡è¿æ¥æµ‹è¯•å¼‚å¸¸: {e}")
        return False, str(e)


def estimate_token_count(text):
    chinese_chars = len(re.findall(r'[\u4e00-\u9fa5]', text))
    english_words = len(re.findall(r'\b[a-zA-Z]+\b', text))
    other_chars = len(text) - chinese_chars - english_words

    estimated_tokens = chinese_chars * 1.5 + english_words * 1 + other_chars * 0.5
    return int(estimated_tokens)


def get_ai_analysis(data_summary, exception_data):
    print(f"    ğŸ§  å¯åŠ¨QWEN3-32B AIå¼•æ“è¿›è¡Œæ·±åº¦åˆ†æ...")
    
    limited_exception_data = limit_exception_data(exception_data, max_items_per_category=50)

    simplified_summary = {
        "æœåŠ¡å™¨çŠ¶æ€": {
            "æ€»æœåŠ¡å™¨æ•°": data_summary["æœåŠ¡å™¨çŠ¶æ€"]["æ€»æœåŠ¡å™¨æ•°"],
            "CPUå¼‚å¸¸": data_summary["æœåŠ¡å™¨çŠ¶æ€"]["CPUå¼‚å¸¸"],
            "å†…å­˜å¼‚å¸¸": data_summary["æœåŠ¡å™¨çŠ¶æ€"]["å†…å­˜å¼‚å¸¸"],
            "ç£ç›˜å¼‚å¸¸": data_summary["æœåŠ¡å™¨çŠ¶æ€"]["ç£ç›˜å¼‚å¸¸"],
            "ç½‘ç»œå¼‚å¸¸": data_summary["æœåŠ¡å™¨çŠ¶æ€"]["ç½‘ç»œå¼‚å¸¸"]
        },
        "æœåŠ¡çŠ¶æ€": {
            "æœåŠ¡æ€»æ•°": data_summary["æœåŠ¡çŠ¶æ€"]["æœåŠ¡æ€»æ•°"],
            "å¼‚å¸¸æœåŠ¡": data_summary["æœåŠ¡çŠ¶æ€"]["å¼‚å¸¸æœåŠ¡"],
            "æœªè¿è¡Œè¿›ç¨‹": data_summary["æœåŠ¡çŠ¶æ€"]["æœªè¿è¡Œè¿›ç¨‹"]
        },
        "å­˜å‚¨çŠ¶æ€": {
            "å­˜å‚¨æ± æ€»æ•°": data_summary["å­˜å‚¨çŠ¶æ€"]["å­˜å‚¨æ± æ€»æ•°"],
            "å¼‚å¸¸å­˜å‚¨æ± ": data_summary["å­˜å‚¨çŠ¶æ€"]["å¼‚å¸¸å­˜å‚¨æ± "],
            "é«˜ä½¿ç”¨ç‡å­˜å‚¨æ± (>80%)": data_summary["å­˜å‚¨çŠ¶æ€"]["é«˜ä½¿ç”¨ç‡å­˜å‚¨æ± (>80%)"]
        },
        "ç”µåŠ›çŠ¶æ€": {
            "ç›‘æ§è®°å½•æ•°": data_summary["ç”µåŠ›çŠ¶æ€"]["ç›‘æ§è®°å½•æ•°"],
            "ç”µæ± å¼‚å¸¸": data_summary["ç”µåŠ›çŠ¶æ€"]["ç”µæ± å¼‚å¸¸"],
            "ç”µå‹å¼‚å¸¸": data_summary["ç”µåŠ›çŠ¶æ€"]["ç”µå‹å¼‚å¸¸"]
        }
    }

    simplified_exceptions = {}
    for category, exceptions in limited_exception_data.items():
        if exceptions:
            if len(exceptions) <= 10:
                simplified_exceptions[category] = exceptions
            else:
                simplified_exceptions[category] = {
                    "è¯¦ç»†ä¿¡æ¯": exceptions[:10],
                    "æ€»æ•°": len(exception_data.get(category, [])),
                    "æ˜¾ç¤ºæ•°": 10,
                    "è¯´æ˜": f"å…±{len(exception_data.get(category, []))}æ¡å¼‚å¸¸ï¼Œä»…æ˜¾ç¤ºå‰10æ¡"
                }

    prompt = f"""
    è¯·ä½œä¸ºæ•°æ®ä¸­å¿ƒè¿ç»´ä¸“å®¶ï¼Œæ ¹æ®ä»¥ä¸‹æ˜¨å¤©çš„æ•°æ®ä¸­å¿ƒç›‘æ§æ•°æ®ï¼Œåˆ†åˆ«æä¾›ä»¥ä¸‹åˆ†æï¼ˆæ³¨æ„å­—æ•°é™åˆ¶ï¼‰ï¼š

    1. è¿ç»´æ—¥æŠ¥(300å­—)ï¼šåŒ…æ‹¬æ•´ä½“è¿è¡ŒçŠ¶å†µæ¦‚è¿°ã€ä¸»è¦æŒ‡æ ‡ã€å…³é”®äº‹ä»¶ç­‰
    2. å¼‚å¸¸åˆ†æ(200å­—)ï¼šå¯¹å‘ç°çš„å¼‚å¸¸æƒ…å†µè¿›è¡ŒåŸå› åˆ†æ
    3. é£é™©é¢„æµ‹(200å­—)ï¼šæ ¹æ®å½“å‰æ•°æ®é¢„æµ‹å¯èƒ½å‡ºç°çš„é£é™©
    4. è¿ç»´å»ºè®®(200å­—)ï¼šé’ˆå¯¹å‘ç°çš„é—®é¢˜æå‡ºå…·ä½“å¯è¡Œçš„è¿ç»´å»ºè®®
    5. é‡ç‚¹å…³æ³¨(200å­—)ï¼šéœ€è¦é‡ç‚¹å…³æ³¨å’Œå¤„ç†çš„é—®é¢˜
    6. ä¸­åº¦å…³æ³¨(200å­—)ï¼šéœ€è¦æŒç»­ç›‘æ§ä½†æš‚ä¸éœ€è¦ç«‹å³å¤„ç†çš„é—®é¢˜

    æ•°æ®æ¦‚å†µï¼š
    {json.dumps(simplified_summary, ensure_ascii=False, indent=2)}

    ä¸»è¦å¼‚å¸¸ä¿¡æ¯ï¼ˆå·²é™åˆ¶æ•°é‡ï¼‰ï¼š
    {json.dumps(simplified_exceptions, ensure_ascii=False, indent=2)}

    è¯·ç¡®ä¿æ¯ä¸ªéƒ¨åˆ†çš„å†…å®¹ä¸“ä¸šã€ç®€æ´ä¸”æœ‰é’ˆå¯¹æ€§ï¼Œä¸è¦è¶…å‡ºå­—æ•°é™åˆ¶ã€‚
    è¯·ç”¨å°æ ‡é¢˜æ ‡ç¤ºæ¯ä¸ªéƒ¨åˆ†ï¼Œç¡®ä¿å¯ä»¥æ¸…æ™°åŒºåˆ†ã€‚
    """

    estimated_tokens = estimate_token_count(prompt)
    print(f"    ğŸ“Š AIè¾“å…¥æ•°æ®é¢„ä¼°tokenæ•°é‡: {estimated_tokens}")
    logger.info(f"ğŸ“Š ä¼°ç®—çš„è¾“å…¥tokenæ•°é‡: {estimated_tokens}")

    if estimated_tokens > 35000:
        print(f"    ğŸ”§ è¾“å…¥æ•°æ®è¿‡å¤§ï¼Œå¯ç”¨æ™ºèƒ½å‹ç¼©...")
        logger.warning(f"âš ï¸ è¾“å…¥æ•°æ®ä»ç„¶è¿‡å¤§ï¼ˆä¼°ç®—{estimated_tokens} tokensï¼‰ï¼Œè¿›ä¸€æ­¥ç®€åŒ–")
        
        simplified_exceptions = {
            category: f"å…±{len(exception_data.get(category, []))}æ¡å¼‚å¸¸"
            for category in limited_exception_data.keys()
        }

        prompt = f"""
        è¯·ä½œä¸ºæ•°æ®ä¸­å¿ƒè¿ç»´ä¸“å®¶ï¼Œæ ¹æ®ä»¥ä¸‹æ˜¨å¤©çš„æ•°æ®ä¸­å¿ƒç›‘æ§æ•°æ®æ¦‚å†µï¼Œæä¾›è¿ç»´åˆ†æï¼š

        æ•°æ®æ¦‚å†µï¼š{json.dumps(simplified_summary, ensure_ascii=False)}
        å¼‚å¸¸ç»Ÿè®¡ï¼š{json.dumps(simplified_exceptions, ensure_ascii=False)}

        è¯·åˆ†åˆ«æä¾›ï¼š
        1. è¿ç»´æ—¥æŠ¥(300å­—)ï¼šæ•´ä½“è¿è¡ŒçŠ¶å†µæ¦‚è¿°
        2. å¼‚å¸¸åˆ†æ(200å­—)ï¼šå¼‚å¸¸æƒ…å†µåŸå› åˆ†æ
        3. é£é™©é¢„æµ‹(200å­—)ï¼šå¯èƒ½å‡ºç°çš„é£é™©
        4. è¿ç»´å»ºè®®(200å­—)ï¼šå…·ä½“å¯è¡Œçš„å»ºè®®
        5. é‡ç‚¹å…³æ³¨(200å­—)ï¼šéœ€è¦é‡ç‚¹å…³æ³¨çš„é—®é¢˜
        6. ä¸­åº¦å…³æ³¨(200å­—)ï¼šéœ€è¦æŒç»­ç›‘æ§çš„é—®é¢˜

        è¯·ç”¨å°æ ‡é¢˜åŒºåˆ†å„éƒ¨åˆ†ã€‚
        """

    url = f"{LLM_CONFIG['base_url']}{LLM_CONFIG['chat_endpoint']}"

    payload = {
        "model": LLM_CONFIG['model_name'],
        "messages": [
            {
                "role": "system",
                "content": "ä½ æ˜¯ä¸€ä½èµ„æ·±çš„æ•°æ®ä¸­å¿ƒè¿ç»´ä¸“å®¶ï¼Œè´Ÿè´£åˆ†ææ˜¨å¤©çš„ç›‘æ§æ•°æ®å¹¶æä¾›ä¸“ä¸šçš„è¿ç»´å»ºè®®ã€‚è¯·ç¡®ä¿å›ç­”ä¸­çš„å…­ä¸ªéƒ¨åˆ†ç”¨æ˜ç¡®çš„æ ‡é¢˜éš”å¼€ï¼Œä¾¿äºè§£æã€‚"
            },
            {
                "role": "user",
                "content": prompt
            }
        ],
        "temperature": 0.7,
        "max_tokens": 1500,
        "stream": False
    }

    headers = {
        "Content-Type": "application/json",
        "Accept": "application/json"
    }

    try:
        print(f"    ğŸŒ å‘AIè¿ç»´å¤§è„‘å‘é€æ·±åº¦åˆ†æè¯·æ±‚...")
        logger.info(f"ğŸ” æ­£åœ¨è¿æ¥AIæœåŠ¡: {url}")
        logger.info(f"ğŸ§  ä½¿ç”¨æ¨¡å‹: {LLM_CONFIG['model_name']}")

        response = requests.post(
            url,
            json=payload,
            headers=headers,
            timeout=120,
            verify=False
        )

        print(f"    ğŸ“¡ AIè¿ç»´å¤§è„‘å“åº”çŠ¶æ€: {response.status_code}")
        logger.info(f"ğŸ“¡ å“åº”çŠ¶æ€ç : {response.status_code}")

        if response.status_code != 200:
            print(f"    âŒ AIè¿ç»´å¤§è„‘è¯·æ±‚å¤±è´¥: {response.status_code}")
            logger.error(f"ğŸš¨ APIè¯·æ±‚å¤±è´¥ï¼ŒçŠ¶æ€ç : {response.status_code}")
            logger.error(f"ğŸš¨ å“åº”å†…å®¹: {response.text}")
            raise Exception(f"APIè¯·æ±‚å¤±è´¥ï¼ŒçŠ¶æ€ç : {response.status_code}, å“åº”: {response.text}")

        try:
            result = response.json()
            print(f"    âœ… AIè¿ç»´å¤§è„‘åˆ†æå®Œæˆï¼Œç”Ÿæˆä¸“ä¸šæ—¥æŠ¥")
            logger.info("ğŸ¯ æˆåŠŸæ¥æ”¶åˆ°AI APIå“åº”")
            logger.debug(f"ğŸ” å“åº”ç»“æ„: {result.keys() if isinstance(result, dict) else 'Not a dict'}")

            if "choices" not in result:
                logger.error(f"ğŸš¨ å“åº”ä¸­ç¼ºå°‘choiceså­—æ®µ: {result}")
                raise Exception(f"APIå“åº”æ ¼å¼å¼‚å¸¸: {result}")

            if not result["choices"] or len(result["choices"]) == 0:
                logger.error("ğŸš¨ å“åº”ä¸­choicesä¸ºç©º")
                raise Exception("APIå“åº”ä¸­choicesä¸ºç©º")

            if "message" not in result["choices"][0]:
                logger.error(f"ğŸš¨ å“åº”ä¸­ç¼ºå°‘messageå­—æ®µ: {result['choices'][0]}")
                raise Exception(f"APIå“åº”æ ¼å¼å¼‚å¸¸ï¼Œç¼ºå°‘messageå­—æ®µ")

            if "content" not in result["choices"][0]["message"]:
                logger.error(f"ğŸš¨ å“åº”ä¸­ç¼ºå°‘contentå­—æ®µ: {result['choices'][0]['message']}")
                raise Exception(f"APIå“åº”æ ¼å¼å¼‚å¸¸ï¼Œç¼ºå°‘contentå­—æ®µ")

            ai_response = result["choices"][0]["message"]["content"]

            if not ai_response or ai_response.strip() == "":
                logger.error("ğŸš¨ AIå“åº”å†…å®¹ä¸ºç©º")
                raise Exception("AIå“åº”å†…å®¹ä¸ºç©º")

            print(f"    ğŸ“ AIåˆ†æç»“æœé•¿åº¦: {len(ai_response)} å­—ç¬¦")
            logger.info(f"ğŸ“ˆ AIå“åº”é•¿åº¦: {len(ai_response)} å­—ç¬¦")
            logger.debug(f"ğŸ“„ AIå“åº”å‰200å­—ç¬¦: {ai_response[:200]}")

            sections = parse_ai_response(ai_response)

            if not any(sections.values()):
                print(f"    âš ï¸ AIåˆ†æç»“æœè§£æåæ‰€æœ‰éƒ¨åˆ†éƒ½ä¸ºç©ºï¼Œä½¿ç”¨åŸå§‹å“åº”")
                logger.warning("âš ï¸ AIå“åº”è§£æåæ‰€æœ‰éƒ¨åˆ†éƒ½ä¸ºç©ºï¼Œä½¿ç”¨åŸå§‹å“åº”")
                return {
                    "è¿ç»´æ—¥æŠ¥": ai_response[:500] if len(ai_response) > 500 else ai_response,
                    "å¼‚å¸¸åˆ†æ": "",
                    "é£é™©é¢„æµ‹": "",
                    "è¿ç»´å»ºè®®": "",
                    "é‡ç‚¹å…³æ³¨": "",
                    "ä¸­åº¦å…³æ³¨": ""
                }

            return sections

        except json.JSONDecodeError as e:
            print(f"    âŒ AIå“åº”JSONæ ¼å¼é”™è¯¯: {e}")
            logger.error(f"ğŸš¨ JSONè§£æå¤±è´¥: {e}")
            logger.error(f"ğŸš¨ å“åº”å†…å®¹: {response.text}")
            raise Exception(f"APIå“åº”JSONæ ¼å¼é”™è¯¯: {e}")

    except requests.exceptions.Timeout:
        print(f"    â° AIè¿ç»´å¤§è„‘è¯·æ±‚è¶…æ—¶")
        logger.error("ğŸš¨ è¯·æ±‚è¶…æ—¶")
        return {
            "è¿ç»´æ—¥æŠ¥": "AIåˆ†ææœåŠ¡è¯·æ±‚è¶…æ—¶ï¼Œè¯·æ£€æŸ¥ç½‘ç»œè¿æ¥æˆ–ç¨åé‡è¯•ã€‚",
            "å¼‚å¸¸åˆ†æ": "",
            "é£é™©é¢„æµ‹": "",
            "è¿ç»´å»ºè®®": "",
            "é‡ç‚¹å…³æ³¨": "",
            "ä¸­åº¦å…³æ³¨": ""
        }
    except requests.exceptions.ConnectionError as e:
        print(f"    ğŸŒ AIè¿ç»´å¤§è„‘è¿æ¥é”™è¯¯: {e}")
        logger.error(f"ğŸš¨ è¿æ¥é”™è¯¯: {e}")
        return {
            "è¿ç»´æ—¥æŠ¥": f"æ— æ³•è¿æ¥åˆ°AIåˆ†ææœåŠ¡ ({url})ï¼Œè¯·æ£€æŸ¥æœåŠ¡çŠ¶æ€å’Œç½‘ç»œè¿æ¥ã€‚",
            "å¼‚å¸¸åˆ†æ": "",
            "é£é™©é¢„æµ‹": "",
            "è¿ç»´å»ºè®®": "",
            "é‡ç‚¹å…³æ³¨": "",
            "ä¸­åº¦å…³æ³¨": ""
        }
    except requests.exceptions.RequestException as e:
        print(f"    ğŸš¨ AIè¿ç»´å¤§è„‘è¯·æ±‚å¼‚å¸¸: {e}")
        logger.error(f"ğŸš¨ è¯·æ±‚å¼‚å¸¸: {e}")
        return {
            "è¿ç»´æ—¥æŠ¥": f"AIåˆ†ææœåŠ¡è¯·æ±‚å¤±è´¥: {str(e)}",
            "å¼‚å¸¸åˆ†æ": "",
            "é£é™©é¢„æµ‹": "",
            "è¿ç»´å»ºè®®": "",
            "é‡ç‚¹å…³æ³¨": "",
            "ä¸­åº¦å…³æ³¨": ""
        }
    except Exception as e:
        print(f"    ğŸ’¥ AIè¿ç»´å¤§è„‘åˆ†æå¼‚å¸¸: {e}")
        logger.error(f"ğŸš¨ AIåˆ†æè°ƒç”¨å¤±è´¥: {e}")
        logger.error(f"ğŸš¨ é”™è¯¯è¯¦æƒ…: {type(e).__name__}: {str(e)}")
        return {
            "è¿ç»´æ—¥æŠ¥": f"AIåˆ†ææœåŠ¡å¼‚å¸¸: {str(e)}",
            "å¼‚å¸¸åˆ†æ": "",
            "é£é™©é¢„æµ‹": "",
            "è¿ç»´å»ºè®®": "",
            "é‡ç‚¹å…³æ³¨": "",
            "ä¸­åº¦å…³æ³¨": ""
        }


def save_analysis_summary(conn, analysis_data, report_date, exception_data):
    print(f"    ğŸ’¾ å‡†å¤‡å°†æ—¥æŠ¥åˆ†æç»“æœå­˜å‚¨åˆ°æ•°æ®åº“...")
    unique_id = generate_unique_id()

    formatted_exception_data = format_exception_data_for_storage(exception_data)

    insert_query = """
                   INSERT INTO operation_analysis_summary
                   (id, report_date, report_type, operation_daily, exception_analysis,
                    exception_data, risk_prediction, operation_suggestion, key_focus,
                    moderate_focus, created_at)
                   VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)
                   """

    with conn.cursor() as cursor:
        cursor.execute(insert_query, (
            unique_id,
            report_date,
            'daily',
            analysis_data.get('è¿ç»´æ—¥æŠ¥', ''),
            analysis_data.get('å¼‚å¸¸åˆ†æ', ''),
            formatted_exception_data,
            analysis_data.get('é£é™©é¢„æµ‹', ''),
            analysis_data.get('è¿ç»´å»ºè®®', ''),
            analysis_data.get('é‡ç‚¹å…³æ³¨', ''),
            analysis_data.get('ä¸­åº¦å…³æ³¨', ''),
            datetime.now()
        ))
    conn.commit()
    print(f"    âœ… æ—¥æŠ¥åˆ†æç»“æœå·²æˆåŠŸå­˜å‚¨ï¼Œè®°å½•ID: {unique_id}")
    logger.info(f"ğŸ“Š åˆ†æç»“æœå·²ä¿å­˜åˆ°æ•°æ®åº“ï¼ŒID: {unique_id}")
    return unique_id


def daily_monitoring_report(params=None):
    try:
        print("ğŸš€ å¯åŠ¨AIæ™ºèƒ½æ—¥æŠ¥ç”Ÿæˆç³»ç»Ÿ...")
        logger.info("ğŸ“Š å¼€å§‹ç”Ÿæˆæ—¥æŠ¥ç›‘æ§æŠ¥å‘Š...")

        print("ğŸ”— æµ‹è¯•AIè¿ç»´å¤§è„‘è¿æ¥çŠ¶æ€...")
        logger.info("ğŸ” æµ‹è¯•AIæœåŠ¡è¿æ¥...")
        connection_ok, connection_msg = test_ai_connection()
        if not connection_ok:
            print(f"âš ï¸ AIè¿ç»´å¤§è„‘è¿æ¥å¼‚å¸¸: {connection_msg}")
            logger.error(f"ğŸš¨ AIæœåŠ¡è¿æ¥å¤±è´¥: {connection_msg}")
        else:
            print(f"âœ… AIè¿ç»´å¤§è„‘è¿æ¥æ­£å¸¸")
            logger.info("ğŸ¯ AIæœåŠ¡è¿æ¥æ­£å¸¸")

        conn = get_connection()

        start_time, end_time, report_date = get_daily_date_range()
        print(f"ğŸ“… è®¾å®šæ—¥æŠ¥åˆ†ææ—¶é—´èŒƒå›´: {start_time.strftime('%Y-%m-%d')} ({report_date.strftime('%A')})")
        logger.info(f"ğŸ“… æŠ¥å‘Šæ—¥æœŸèŒƒå›´: {start_time} åˆ° {end_time}")

        print(f"ğŸ“Š å¼€å§‹é‡‡é›†å¤šç»´åº¦ç›‘æ§æ•°æ®...")
        server_metrics = fetch_server_metrics(conn, start_time, end_time)
        logger.info(f"ğŸ“ˆ è·å–åˆ° {len(server_metrics)} æ¡æœåŠ¡å™¨æŒ‡æ ‡æ•°æ®")

        service_status = fetch_service_status(conn, start_time, end_time)
        logger.info(f"ğŸ”§ è·å–åˆ° {len(service_status)} æ¡æœåŠ¡çŠ¶æ€æ•°æ®")

        nas_pools = fetch_nas_pools(conn, start_time.date(), end_time.date())
        logger.info(f"ğŸ’¾ è·å–åˆ° {len(nas_pools)} æ¡NASå­˜å‚¨æ± æ•°æ®")

        power_monitoring = fetch_power_monitoring(conn, start_time, end_time)
        logger.info(f"âš¡ è·å–åˆ° {len(power_monitoring)} æ¡ç”µåŠ›ç›‘æ§æ•°æ®")

        if not server_metrics and not service_status and not nas_pools and not power_monitoring:
            print("âš ï¸ æœªå‘ç°å¯åˆ†æçš„æ—¥æŠ¥æ•°æ®")
            logger.warning("âš ï¸ æ²¡æœ‰å¯ç”¨äºåˆ†æçš„æ•°æ®")
            conn.close()
            return {"success": False, "message": "æ²¡æœ‰å¯ç”¨äºåˆ†æçš„æ•°æ®"}

        print(f"ğŸ”§ å¼€å§‹æ•°æ®èšåˆå’Œå¼‚å¸¸è¯†åˆ«...")
        exception_data = get_exceptions(server_metrics, service_status, nas_pools, power_monitoring)
        data_summary = prepare_data_summary(server_metrics, service_status, nas_pools, power_monitoring)

        print(f"ğŸ§  å¯åŠ¨AIæ·±åº¦åˆ†æå¼•æ“...")
        analysis_result = get_ai_analysis(data_summary, exception_data)
        logger.info("ğŸ¯ AIåˆ†æå®Œæˆ")

        print(f"ğŸ’¾ ä¿å­˜åˆ†æç»“æœåˆ°è¿ç»´æ•°æ®åº“...")
        summary_id = save_analysis_summary(conn, analysis_result, report_date, exception_data)

        conn.close()

        result = {
            "success": True,
            "summary_id": summary_id,
            "report_date": report_date.strftime('%Y-%m-%d'),
            "report_type": "daily",
            "analysis": analysis_result,
            "data_summary": data_summary,
            "exception_data": exception_data,
            "exception_count": {
                "server_exceptions": len(exception_data.get("æœåŠ¡å™¨å¼‚å¸¸", [])),
                "service_exceptions": len(exception_data.get("æœåŠ¡å¼‚å¸¸", [])),
                "storage_exceptions": len(exception_data.get("å­˜å‚¨å¼‚å¸¸", [])),
                "power_exceptions": len(exception_data.get("ç”µåŠ›å¼‚å¸¸", []))
            },
            "timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
            "ai_connection_status": connection_msg
        }

        print(f"âœ… AIæ™ºèƒ½æ—¥æŠ¥ç”Ÿæˆå®Œæˆ")
        print(f"ğŸ“Š åˆ†ææ—¥æœŸ: {report_date.strftime('%Y-%m-%d')}")
        print(f"ğŸ“‹ æŠ¥å‘ŠID: {summary_id}")
        print(f"ğŸ“ˆ å‘ç°å¼‚å¸¸: {sum(result['exception_count'].values())} é¡¹")

        logger.info(f"ğŸ“Š æ—¥æŠ¥ç”Ÿæˆå®Œæˆï¼Œå…±å‘ç° {sum(result['exception_count'].values())} é¡¹å¼‚å¸¸")
        return result

    except Exception as e:
        print(f"âŒ AIæ™ºèƒ½æ—¥æŠ¥ç³»ç»Ÿæ‰§è¡Œå¼‚å¸¸: {e}")
        logger.error(f"ğŸš¨ ç”Ÿæˆæ—¥æŠ¥ç›‘æ§æŠ¥å‘Šæ—¶å‘ç”Ÿé”™è¯¯: {e}")
        return {"success": False, "error": str(e)}


if __name__ == "__main__":
    result = daily_monitoring_report()
    print(f"æµ‹è¯•ç»“æœ: {json.dumps(result, ensure_ascii=False, indent=2)}")
