#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import asyncio
import json
import os
import requests
import sys
from datetime import datetime

project_root = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
sys.path.append(project_root)

from utils.logger import setup_logger

logger = setup_logger(__name__)

LLM_CONFIG = {
    'base_url': 'http://192.168.101.214:6007',
    'chat_endpoint': '/v1/chat/completions',
    'model_name': 'Qwen3-32B-AWQ'
}

class FullInspectionRunner:
    def __init__(self, mcp_server=None):
        self.mcp_server = mcp_server
        self.system_file = os.path.join(project_root, 'services', 'data', 'system.json')
        self.llm_config = LLM_CONFIG

    def load_system_data(self):
        try:
            with open(self.system_file, 'r', encoding='utf-8') as f:
                return json.load(f)
        except Exception as e:
            logger.error(f"è¯»å–ç³»ç»Ÿæ–‡ä»¶å¤±è´¥: {e}")
            return None

    def call_llm(self, prompt, temperature=0.3, max_tokens=800):
        try:
            url = f"{self.llm_config['base_url']}{self.llm_config['chat_endpoint']}"
            payload = {
                "model": self.llm_config['model_name'],
                "messages": [
                    {"role": "system",
                     "content": "ä½ æ˜¯ä¸€ä¸ªæ™ºèƒ½è¿ç»´è°ƒåº¦ä¸“å®¶ï¼Œè´Ÿè´£æ§åˆ¶ç¡¬ä»¶å·¡æ£€æµç¨‹ã€‚ä½ éœ€è¦æ ¹æ®å½“å‰çŠ¶æ€å†³å®šä¸‹ä¸€æ­¥åº”è¯¥æ‰§è¡Œå“ªä¸ªMCPæœåŠ¡ã€‚"},
                    {"role": "user", "content": prompt}
                ],
                "temperature": temperature,
                "max_tokens": max_tokens
            }

            headers = {"Content-Type": "application/json"}
            response = requests.post(url, json=payload, headers=headers, timeout=30)
            response.raise_for_status()

            result = response.json()
            return result["choices"][0]["message"]["content"]
        except Exception as e:
            logger.error(f"LLMè°ƒç”¨å¤±è´¥: {e}")
            return None

    def parse_llm_decision(self, llm_response):
        try:
            import re
            json_match = re.search(r'\{.*\}', llm_response, re.DOTALL)
            if json_match:
                return json.loads(json_match.group())
        except:
            pass
        return None

    async def call_mcp_tool(self, tool_name, params=None):
        if params is None:
            params = {}

        request_data = json.dumps({
            "method": "call_tool",
            "params": {
                "name": tool_name,
                "arguments": params
            },
            "id": f"full_inspection_{tool_name}"
        })

        response_str = await self.mcp_server.handle_request(request_data)
        response = json.loads(response_str)
        return response

    async def get_next_step_from_llm(self, current_step, execution_results, available_services):
        executed_services = [step['service'] for step in execution_results.get('steps', [])]

        prompt = f"""
å½“å‰ç¡¬ä»¶å·¡æ£€æµç¨‹çŠ¶æ€ï¼š
- å½“å‰æ­¥éª¤: {current_step}
- å·²æ‰§è¡Œçš„æœåŠ¡: {executed_services}
- å·²æ‰§è¡Œç»“æœ: {json.dumps(execution_results, ensure_ascii=False, indent=2)}

å¯ç”¨çš„MCPæœåŠ¡ï¼š
{json.dumps(available_services, ensure_ascii=False, indent=2)}

è¯·åˆ†æå½“å‰çŠ¶æ€å¹¶å†³å®šä¸‹ä¸€æ­¥åº”è¯¥æ‰§è¡Œå“ªä¸ªæœåŠ¡ã€‚è¿”å›JSONæ ¼å¼ï¼š
{{
    "next_service": "æœåŠ¡åç§°æˆ–null",
    "reason": "é€‰æ‹©åŸå› ",
    "params": {{"å‚æ•°": "å€¼"}},
    "should_continue": true/false,
    "message": "ç»™ç”¨æˆ·çš„æ¶ˆæ¯"
}}

å†³ç­–è§„åˆ™ï¼š
1. å¦‚æœæ˜¯ç¬¬ä¸€æ­¥(current_step=0)ï¼Œæ‰§è¡Œservice_001_system_inspectionè¿›è¡Œç³»ç»Ÿå·¡æ£€
2. ç³»ç»Ÿå·¡æ£€å®Œæˆåï¼Œæ ¹æ®å¼‚å¸¸IPåˆ—è¡¨æ‰§è¡Œå†…å­˜å·¡æ£€service_002_memory_inspection
3. å†…å­˜å·¡æ£€å®Œæˆåï¼Œæ‰§è¡Œç¡¬ç›˜å·¡æ£€service_003_disk_inspection
4. å†…å­˜å’Œç¡¬ç›˜å·¡æ£€éƒ½å®Œæˆåï¼Œæ‰§è¡Œservice_004_hardware_summaryç”ŸæˆAIæŠ¥å‘Š
5. AIæŠ¥å‘Šç”Ÿæˆå®Œæˆåï¼Œæ‰§è¡Œservice_011_apply_purchasesè¿›è¡Œå†…å­˜å‡çº§å»ºè®®(ä¸ç­‰å¾…å›å¤)
6. å†…å­˜å‡çº§å»ºè®®å®Œæˆåï¼Œè¿”å›should_continue: falseç»“æŸæµç¨‹
7. å¦‚æœå‰ä¸€æ­¥å¤±è´¥ï¼Œåˆ†ææ˜¯å¦å¯ä»¥ç»§ç»­ä¸‹ä¸€æ­¥

é‡è¦ï¼šåªæœ‰å½“æ‰€æœ‰5ä¸ªæ ¸å¿ƒæœåŠ¡éƒ½æ‰§è¡Œå®Œæˆåæ‰èƒ½è®¾ç½®should_continue: false
"""

        response = self.call_llm(prompt)
        if response:
            decision = self.parse_llm_decision(response)
            if decision:
                return decision

        executed_services = [step['service'] for step in execution_results.get('steps', [])]

        if current_step == 0:
            return {
                "next_service": "service_001_system_inspection",
                "reason": "å¼€å§‹æ‰§è¡Œç³»ç»Ÿå·¡æ£€",
                "params": {},
                "should_continue": True,
                "message": "æ‰§è¡Œç³»ç»Ÿå·¡æ£€ä»¥è·å–å¼‚å¸¸æœåŠ¡å™¨åˆ—è¡¨"
            }
        elif "service_001_system_inspection" in executed_services and "service_002_memory_inspection" not in executed_services:
            return {
                "next_service": "service_002_memory_inspection",
                "reason": "ç³»ç»Ÿå·¡æ£€å®Œæˆï¼Œå¼€å§‹å†…å­˜å·¡æ£€",
                "params": {},
                "should_continue": True,
                "message": "æ‰§è¡Œå†…å­˜è¯¦ç»†å·¡æ£€"
            }
        elif "service_002_memory_inspection" in executed_services and "service_003_disk_inspection" not in executed_services:
            return {
                "next_service": "service_003_disk_inspection",
                "reason": "å†…å­˜å·¡æ£€å®Œæˆï¼Œå¼€å§‹ç¡¬ç›˜å·¡æ£€",
                "params": {},
                "should_continue": True,
                "message": "æ‰§è¡Œç¡¬ç›˜è¯¦ç»†å·¡æ£€"
            }
        elif ("service_002_memory_inspection" in executed_services and
              "service_003_disk_inspection" in executed_services and
              "service_004_hardware_summary" not in executed_services):
            return {
                "next_service": "service_004_hardware_summary",
                "reason": "å†…å­˜å’Œç¡¬ç›˜å·¡æ£€å®Œæˆï¼Œç”ŸæˆAIåˆ†ææŠ¥å‘Š",
                "params": {},
                "should_continue": True,
                "message": "ç”Ÿæˆç¡¬ä»¶å·¡æ£€AIåˆ†ææŠ¥å‘Š"
            }
        elif ("service_004_hardware_summary" in executed_services and
              "service_011_apply_purchases" not in executed_services):
            return {
                "next_service": "service_011_apply_purchases",
                "reason": "AIåˆ†ææŠ¥å‘Šå®Œæˆï¼Œå¼€å§‹å†…å­˜å‡çº§å»ºè®®",
                "params": {"wait_for_approval": False},
                "should_continue": True,
                "message": "ç”Ÿæˆå†…å­˜å‡çº§å»ºè®®"
            }
        else:
            return {
                "next_service": None,
                "reason": "æ‰€æœ‰å·¡æ£€æ­¥éª¤å·²å®Œæˆ",
                "params": {},
                "should_continue": False,
                "message": "ç¡¬ä»¶å·¡æ£€æµç¨‹æ‰§è¡Œå®Œæˆ"
            }

    async def run_full_inspection(self, params=None):
        logger.info("ã€æœåŠ¡005ã€‘å¼€å§‹æ‰§è¡Œå®Œæ•´å·¡æ£€æµç¨‹ - é€šè¿‡å¤§æ¨¡å‹æ™ºèƒ½è°ƒåº¦")
        print("=== ç¡¬ä»¶å·¡æ£€æ™ºèƒ½åŠ©æ‰‹ - AIé©±åŠ¨çš„å®Œæ•´å·¡æ£€æµç¨‹ ===")

        hours = params.get('hours', 6) if params else 6
        memory_threshold = params.get('memory_threshold', 70) if params else 70
        disk_threshold = params.get('disk_threshold', 80) if params else 80
        wait_for_approval = params.get('wait_for_approval', False) if params else False

        execution_results = {
            'start_time': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
            'parameters': {
                'hours': hours,
                'memory_threshold': memory_threshold,
                'disk_threshold': disk_threshold,
                'wait_for_approval': wait_for_approval
            },
            'steps': [],
            'status': 'running',
            'end_time': None,
            'ai_decisions': []
        }

        available_services = [
            {
                "name": "service_001_system_inspection",
                "description": "ç³»ç»Ÿå·¡æ£€ - æŸ¥è¯¢æ•°æ®åº“è·å–å¼‚å¸¸æœåŠ¡å™¨åˆ—è¡¨",
                "step_order": 1
            },
            {
                "name": "service_002_memory_inspection",
                "description": "å†…å­˜å·¡æ£€ - SSHè¿æ¥è¯¦ç»†æ£€æŸ¥å†…å­˜",
                "step_order": 2
            },
            {
                "name": "service_003_disk_inspection",
                "description": "ç¡¬ç›˜å·¡æ£€ - SSHè¿æ¥è¯¦ç»†æ£€æŸ¥ç¡¬ç›˜",
                "step_order": 3
            },
            {
                "name": "service_004_hardware_summary",
                "description": "AIåˆ†ææŠ¥å‘Š - ç”Ÿæˆæ™ºèƒ½åˆ†ææŠ¥å‘Š",
                "step_order": 4
            },
            {
                "name": "service_011_apply_purchases",
                "description": "å†…å­˜å‡çº§å»ºè®® - ç”Ÿæˆå†…å­˜å‡çº§å»ºè®®",
                "step_order": 5
            }
        ]

        current_step = 0
        max_steps = 15

        try:
            while current_step < max_steps:
                print(f"\nğŸ¤– AIæ­£åœ¨åˆ†æå½“å‰çŠ¶æ€å¹¶å†³å®šä¸‹ä¸€æ­¥æ“ä½œ...")

                decision = await self.get_next_step_from_llm(
                    current_step,
                    execution_results,
                    available_services
                )

                execution_results['ai_decisions'].append({
                    'step': current_step + 1,
                    'decision': decision,
                    'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
                })

                print(f"ğŸ“‹ AIå†³ç­–: {decision.get('message', 'æœªçŸ¥å†³ç­–')}")
                logger.info(f"AIå†³ç­–: {decision}")

                next_service = decision.get('next_service')
                if not next_service:
                    print("ğŸ¯ AIåˆ¤æ–­æµç¨‹åº”è¯¥ç»“æŸ")
                    break

                print(f"âš™ï¸  æ‰§è¡ŒæœåŠ¡: {next_service}")
                print(f"ğŸ“ æ‰§è¡ŒåŸå› : {decision.get('reason', 'æœªçŸ¥åŸå› ')}")

                service_params = decision.get('params', {})

                if next_service == "service_001_system_inspection":
                    service_params.update({
                        "hours": hours,
                        "memory_threshold": memory_threshold,
                        "disk_threshold": disk_threshold
                    })

                elif next_service in ["service_002_memory_inspection", "service_003_disk_inspection"]:
                    system_data = self.load_system_data()
                    if system_data:
                        if next_service == "service_002_memory_inspection":
                            ip_list = system_data.get('abnormal_memory_ips', [])
                        else:
                            ip_list = system_data.get('abnormal_disk_ips', [])

                        if ip_list:
                            service_params['ip_list'] = ip_list
                        else:
                            print(f"ğŸ“‹ è·³è¿‡ {next_service} - æœªå‘ç°éœ€è¦å·¡æ£€çš„IP")

                elif next_service == "service_011_apply_purchases":
                    service_params['wait_for_approval'] = wait_for_approval

                print(f"ğŸ”„ æ­£åœ¨æ‰§è¡Œ {next_service}...")
                result = await self.call_mcp_tool(next_service, service_params)

                step_result = {
                    'step': current_step + 1,
                    'service': next_service,
                    'status': 'success' if result.get('success') else 'failed',
                    'message': result.get('data', {}).get('message', '') if result.get('success') else result.get(
                        'error', ''),
                    'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
                    'ai_reason': decision.get('reason', ''),
                    'params': service_params,
                    'result_data': result.get('data', {}) if result.get('success') else None
                }

                if result.get('success'):
                    print(f"âœ… {next_service} æ‰§è¡ŒæˆåŠŸ")
                    data = result.get('data', {})
                    if 'successful_count' in data:
                        print(
                            f"   æˆåŠŸ: {data.get('successful_count', 0)}å°, æ— æƒé™: {data.get('no_permission_count', 0)}å°")

                    if 'output_file' in data:
                        print(f"   è¾“å‡ºæ–‡ä»¶: {data['output_file']}")

                    if 'records_count' in data:
                        print(f"   ç”Ÿæˆè®°å½•: {data.get('records_count', 0)}æ¡")

                else:
                    step_result['error'] = result.get('error')
                    print(f"âŒ {next_service} æ‰§è¡Œå¤±è´¥: {result.get('error')}")

                execution_results['steps'].append(step_result)
                current_step += 1

                if next_service == "service_001_system_inspection" and result.get('success'):
                    system_data = self.load_system_data()
                    if system_data:
                        abnormal_memory_ips = system_data.get('abnormal_memory_ips', [])
                        abnormal_disk_ips = system_data.get('abnormal_disk_ips', [])
                        print(f"   å‘ç°å¼‚å¸¸å†…å­˜æœåŠ¡å™¨: {len(abnormal_memory_ips)}å° {abnormal_memory_ips}")
                        print(f"   å‘ç°å¼‚å¸¸ç¡¬ç›˜æœåŠ¡å™¨: {len(abnormal_disk_ips)}å° {abnormal_disk_ips}")

                if not decision.get('should_continue', False):
                    print("ğŸ¯ AIåˆ¤æ–­å½“å‰æ­¥éª¤å®Œæˆåæµç¨‹ç»“æŸ")
                    break

                await asyncio.sleep(1)

            execution_results['status'] = 'completed'
            execution_results['end_time'] = datetime.now().strftime('%Y-%m-%d %H:%M:%S')

            print("\n=== AIé©±åŠ¨çš„å®Œæ•´å·¡æ£€æµç¨‹æ‰§è¡Œå®Œæˆ ===")
            print("ğŸ“ ç”Ÿæˆçš„ç»“æœæ–‡ä»¶:")
            print(f"   - {self.system_file} (ç³»ç»Ÿå·¡æ£€ç»“æœ)")
            print("   - services/data/memory_inspection.json (å†…å­˜å·¡æ£€ç»“æœ)")
            print("   - services/data/disk_inspection.json (ç¡¬ç›˜å·¡æ£€ç»“æœ)")
            print("   - services/data/hardware_summary.txt (AIåˆ†ææŠ¥å‘Š)")
            print("   - services/data/memory_update.json (å†…å­˜å‡çº§å»ºè®®)")
            print(f"ğŸ¤– AIå…±åšå‡º {len(execution_results['ai_decisions'])} æ¬¡å†³ç­–")
            print(f"ğŸ“Š æˆåŠŸæ‰§è¡Œ {len([s for s in execution_results['steps'] if s['status'] == 'success'])} ä¸ªæœåŠ¡")

            logger.info("ã€æœåŠ¡005ã€‘AIé©±åŠ¨çš„å®Œæ•´å·¡æ£€æµç¨‹æ‰§è¡Œå®Œæˆ")

            return execution_results

        except Exception as e:
            execution_results['status'] = 'failed'
            execution_results['error'] = str(e)
            execution_results['end_time'] = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
            logger.error(f"ã€æœåŠ¡005ã€‘å®Œæ•´å·¡æ£€æµç¨‹æ‰§è¡Œå¤±è´¥: {e}")
            print(f"âŒ å®Œæ•´å·¡æ£€æµç¨‹æ‰§è¡Œå¤±è´¥: {e}")
            return execution_results

async def full_inspection(params=None, mcp_server=None):
    try:
        print("ã€æœåŠ¡005ã€‘AIé©±åŠ¨çš„ç¡¬ä»¶å·¡æ£€å®Œæ•´æµç¨‹å¯åŠ¨")
        logger.info("ã€æœåŠ¡005ã€‘å¼€å§‹æ‰§è¡ŒAIé©±åŠ¨çš„ç¡¬ä»¶å·¡æ£€å®Œæ•´æµç¨‹")

        if not mcp_server:
            return {"success": False, "error": "ç¼ºå°‘MCPæœåŠ¡å™¨å®ä¾‹"}

        runner = FullInspectionRunner(mcp_server)
        results = await runner.run_full_inspection(params)

        if results['status'] == 'completed':
            return {
                "success": True,
                "message": "AIé©±åŠ¨çš„å®Œæ•´å·¡æ£€æµç¨‹æ‰§è¡Œå®Œæˆ",
                "timestamp": datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
                "execution_results": results
            }
        else:
            return {
                "success": False,
                "error": f"å®Œæ•´å·¡æ£€æµç¨‹æ‰§è¡Œå¤±è´¥: {results.get('error', 'æœªçŸ¥é”™è¯¯')}",
                "execution_results": results
            }

    except Exception as e:
        error_msg = f"ã€æœåŠ¡005ã€‘å®Œæ•´å·¡æ£€æµç¨‹å¼‚å¸¸: {str(e)}"
        print(error_msg)
        logger.error(error_msg)
        return {"success": False, "error": error_msg}

async def main():
    print("ç‹¬ç«‹è¿è¡Œæ¨¡å¼ - éœ€è¦MCPæœåŠ¡å™¨å®ä¾‹")
    print("è¯·é€šè¿‡MCPæœåŠ¡å™¨è°ƒç”¨æ­¤æœåŠ¡")

if __name__ == "__main__":
    asyncio.run(main())